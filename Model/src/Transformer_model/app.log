2024-11-28 17:09:53,537 [INFO] Loading base model.
2024-11-28 17:09:54,329 [INFO] Model and tokenizer loaded successfully.
2024-11-28 17:10:08,390 [INFO] 127.0.0.1 - - [28/Nov/2024 17:10:08] "GET /get_training_status HTTP/1.1" 200 -
2024-11-28 17:10:29,601 [INFO] File saved to ./uploads\8302efe7-c3d2-477f-b6b5-bdc3c130bf36_SMILES_Big_Data_Set.csv
2024-11-28 17:10:29,602 [INFO] Starting training with file: ./uploads\8302efe7-c3d2-477f-b6b5-bdc3c130bf36_SMILES_Big_Data_Set.csv
2024-11-28 17:10:29,603 [INFO] 127.0.0.1 - - [28/Nov/2024 17:10:29] "[35m[1mPOST /train HTTP/1.1[0m" 202 -
2024-11-28 17:10:34,222 [INFO] Initial number of samples: 16087
2024-11-28 17:10:34,224 [WARNING] Non-numeric rows found and will be removed:
2024-11-28 17:10:34,224 [WARNING]        pIC50  num_atoms    logP
1915     NaN         24 -1.6512
1919     NaN          6 -0.5482
1940     NaN         12 -3.5854
1941     NaN         10 -2.0785
1944     NaN         12 -1.4074
...      ...        ...     ...
16028    NaN         23 -1.7679
16031    NaN         22 -0.1401
16032    NaN         15 -1.7052
16033    NaN         13 -0.2429
16034    NaN         22 -2.1580

[1050 rows x 3 columns]
2024-11-28 17:10:34,249 [INFO] Number of samples with NaN values removed: 15037
2024-11-28 17:10:34,250 [INFO] Final number of SMILES: 15037
2024-11-28 17:10:34,250 [INFO] Final number of targets: 15037
2024-11-28 17:11:00,044 [INFO] Loading fine-tuned model from ./models\fine_tuned_model_20241128_171034
2024-11-28 17:11:00,046 [ERROR] Error loading model and tokenizer: Unrecognized model in ./models\fine_tuned_model_20241128_171034. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-11-28 17:11:27,567 [INFO] Loading fine-tuned model from ./models\fine_tuned_model_20241128_171034
2024-11-28 17:11:27,568 [ERROR] Error loading model and tokenizer: Unrecognized model in ./models\fine_tuned_model_20241128_171034. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-11-28 17:13:11,770 [INFO] Loading fine-tuned model from ./models\fine_tuned_model_20241128_171034\custom_model.pth
2024-11-28 17:13:11,770 [ERROR] Error loading model and tokenizer: Unrecognized model in ./models\fine_tuned_model_20241128_171034. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:17:13,410 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:17:14,148 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:17:14,622 [WARNING]  * Debugger is active!
2024-12-08 18:17:14,634 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 18:17:43,741 [INFO] Training started.
2024-12-08 18:17:43,744 [INFO] 127.0.0.1 - - [08/Dec/2024 18:17:43] "[35m[1mPOST /train HTTP/1.1[0m" 202 -
2024-12-08 18:18:21,549 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:21] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:26,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:31,524 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:31] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:36,222 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:41,526 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:41] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:46,452 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:46] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:51,103 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:51] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:18:56,012 [INFO] 127.0.0.1 - - [08/Dec/2024 18:18:56] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:00,704 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:00] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:06,013 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:11,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:11] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:16,521 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:21,211 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:21] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:26,529 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:31,209 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:31] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:36,016 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:41,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:41] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:46,530 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:46] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:50,704 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:50] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:19:56,026 [INFO] 127.0.0.1 - - [08/Dec/2024 18:19:56] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:01,155 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:01] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:06,528 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:11,219 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:11] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:16,532 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:20,701 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:20] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:26,533 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:31,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:31] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:36,541 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:41,209 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:41] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:46,517 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:46] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:51,213 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:51] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:20:56,527 [INFO] 127.0.0.1 - - [08/Dec/2024 18:20:56] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:01,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:01] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:06,522 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:11,206 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:11] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:16,522 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:21,208 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:21] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:26,527 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:31,207 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:31] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:36,526 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:49,215 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:21:57,584 [INFO] 127.0.0.1 - - [08/Dec/2024 18:21:57] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:00,695 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:00] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:06,014 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:10,692 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:10] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:16,019 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:20,705 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:20] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:26,010 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:30,720 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:30] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:36,016 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:40,697 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:40] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:46,006 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:46] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:51,209 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:51] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:22:56,516 [INFO] 127.0.0.1 - - [08/Dec/2024 18:22:56] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:01,225 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:01] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:06,529 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:11,203 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:11] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:16,521 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:21,215 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:21] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:26,388 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:31,241 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:31] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:36,539 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:36] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:41,210 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:41] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:46,533 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:46] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:51,209 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:51] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:23:56,525 [INFO] 127.0.0.1 - - [08/Dec/2024 18:23:56] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:01,253 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:01] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:06,524 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:06] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:11,250 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:11] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:16,533 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:16] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:21,531 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:21] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:26,215 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:26] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:24:49,519 [INFO] 127.0.0.1 - - [08/Dec/2024 18:24:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:25:49,526 [INFO] 127.0.0.1 - - [08/Dec/2024 18:25:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:26:49,202 [INFO] 127.0.0.1 - - [08/Dec/2024 18:26:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:27:49,532 [INFO] 127.0.0.1 - - [08/Dec/2024 18:27:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:28:49,210 [INFO] 127.0.0.1 - - [08/Dec/2024 18:28:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:29:49,532 [INFO] 127.0.0.1 - - [08/Dec/2024 18:29:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:30:49,230 [INFO] 127.0.0.1 - - [08/Dec/2024 18:30:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:31:49,535 [INFO] 127.0.0.1 - - [08/Dec/2024 18:31:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:32:21,675 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:32:22,710 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:32:23,262 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-08 18:32:23,263 [INFO] [33mPress CTRL+C to quit[0m
2024-12-08 18:32:23,265 [INFO]  * Restarting with stat
2024-12-08 18:32:30,176 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:32:31,035 [INFO] Loading base pre-trained ChemBERTa model.
2024-12-08 18:32:31,554 [WARNING]  * Debugger is active!
2024-12-08 18:32:31,566 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 18:32:31,599 [INFO] Training started.
2024-12-08 18:32:31,600 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:31] "[35m[1mPOST /train HTTP/1.1[0m" 202 -
2024-12-08 18:32:39,206 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:32:44,518 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:44] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:32:49,523 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:32:54,209 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:54] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:32:59,533 [INFO] 127.0.0.1 - - [08/Dec/2024 18:32:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:04,522 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:04] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:09,206 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:14,521 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:14] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:19,205 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:24,527 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:24] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:29,227 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:34,033 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:34] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:39,028 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:43,712 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:43] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:49,523 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:53,721 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:53] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:33:59,036 [INFO] 127.0.0.1 - - [08/Dec/2024 18:33:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:04,213 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:04] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:09,528 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:13,721 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:13] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:19,532 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:24,223 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:24] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:29,514 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:34,214 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:34] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:39,523 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:44,534 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:44] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:49,221 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:54,523 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:54] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:34:59,211 [INFO] 127.0.0.1 - - [08/Dec/2024 18:34:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:35:04,520 [INFO] 127.0.0.1 - - [08/Dec/2024 18:35:04] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:35:09,221 [INFO] 127.0.0.1 - - [08/Dec/2024 18:35:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:35:14,519 [INFO] 127.0.0.1 - - [08/Dec/2024 18:35:14] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:35:49,245 [INFO] 127.0.0.1 - - [08/Dec/2024 18:35:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:04,723 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:04] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:08,720 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:08] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:14,031 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:14] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:18,717 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:18] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:24,024 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:24] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:28,718 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:28] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:34,029 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:34] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:38,710 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:38] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:44,024 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:44] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:49,213 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:54,526 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:54] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:36:59,219 [INFO] 127.0.0.1 - - [08/Dec/2024 18:36:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:04,529 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:04] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:09,218 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:14,520 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:14] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:19,226 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:24,526 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:24] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:29,220 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:34,518 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:34] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:39,216 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:44,532 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:44] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:37:49,226 [INFO] 127.0.0.1 - - [08/Dec/2024 18:37:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:38:49,533 [INFO] 127.0.0.1 - - [08/Dec/2024 18:38:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:24,621 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:24] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:29,026 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:33,719 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:33] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:39,019 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:43,713 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:43] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:49,038 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:53,721 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:53] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:39:59,036 [INFO] 127.0.0.1 - - [08/Dec/2024 18:39:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:03,724 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:03] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:09,028 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:13,714 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:13] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:19,019 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:23,722 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:23] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:29,029 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:33,712 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:33] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:39,038 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:43,721 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:43] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:49,032 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:53,713 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:53] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:40:59,029 [INFO] 127.0.0.1 - - [08/Dec/2024 18:40:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:03,725 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:03] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:09,030 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:13,719 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:13] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:19,041 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:23,719 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:23] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:29,027 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:33,717 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:33] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:39,029 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:43,720 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:43] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:49,034 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:53,714 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:53] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:41:59,036 [INFO] 127.0.0.1 - - [08/Dec/2024 18:41:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:03,720 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:03] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:09,022 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:09] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:14,212 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:14] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:19,034 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:19] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:23,711 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:23] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:29,022 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:29] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:33,717 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:33] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:39,033 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:39] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:44,205 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:44] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:49,527 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:49] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:54,245 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:54] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:42:58,987 [INFO] Fine-tuned model saved to ./fine_tuned_model
2024-12-08 18:42:59,527 [INFO] 127.0.0.1 - - [08/Dec/2024 18:42:59] "GET /get_training_status HTTP/1.1" 200 -
2024-12-08 18:43:00,652 [INFO] Custom model state_dict saved to ./fine_tuned_model\custom_model_state_dict.pt
2024-12-08 18:43:00,656 [ERROR] Training error: Unrecognized model in ./fine_tuned_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:46:37,990 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 18:46:39,708 [INFO]  * Restarting with stat
2024-12-08 18:46:49,715 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:46:49,716 [ERROR] Error loading fine-tuned model: Unrecognized model in ./fine_tuned_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:46:50,818 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:46:50,820 [ERROR] Error loading fine-tuned model: Unrecognized model in ./fine_tuned_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:46:51,437 [WARNING]  * Debugger is active!
2024-12-08 18:46:51,455 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 18:46:57,588 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 18:46:58,195 [INFO]  * Restarting with stat
2024-12-08 18:47:05,155 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:47:05,156 [ERROR] Error loading fine-tuned model: Unrecognized model in ./fine_tuned_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:47:05,889 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:47:05,890 [ERROR] Error loading fine-tuned model: Unrecognized model in ./fine_tuned_model. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deformable_detr, deit, depth_anything, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, falcon_mamba, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, git, glm, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, granite, granitemoe, graphormer, grounding-dino, groupvit, hiera, hubert, ibert, idefics, idefics2, idefics3, imagegpt, informer, instructblip, instructblipvideo, jamba, jetmoe, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, mistral, mixtral, mllama, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, phi3, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso, zamba, zoedepth
2024-12-08 18:47:06,352 [WARNING]  * Debugger is active!
2024-12-08 18:47:06,365 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 18:49:10,294 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 18:49:11,873 [INFO]  * Restarting with stat
2024-12-08 18:49:22,839 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:49:23,019 [ERROR] Error loading fine-tuned model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:49:23,023 [ERROR] Error loading base model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:49:23,217 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:49:23,230 [ERROR] Error loading fine-tuned model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:49:23,234 [ERROR] Error loading base model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:49:23,252 [WARNING]  * Debugger is active!
2024-12-08 18:49:23,273 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 18:49:34,485 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 18:49:35,396 [INFO]  * Restarting with stat
2024-12-08 18:50:15,000 [INFO]  * Restarting with stat
2024-12-08 18:55:17,775 [INFO]  * Restarting with stat
2024-12-08 18:55:30,865 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:55:31,038 [ERROR] Error loading fine-tuned model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:55:31,042 [ERROR] Error loading base model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:55:31,234 [INFO] Loading fine-tuned model from ./fine_tuned_model
2024-12-08 18:55:31,246 [ERROR] Error loading fine-tuned model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:55:31,250 [ERROR] Error loading base model: Unrecognized configuration class <class '__main__.KnowledgeAugmentedConfig'> for this kind of AutoModel: AutoModelForSequenceClassification.
Model type should be one of AlbertConfig, BartConfig, BertConfig, BigBirdConfig, BigBirdPegasusConfig, BioGptConfig, BloomConfig, CamembertConfig, CanineConfig, LlamaConfig, ConvBertConfig, CTRLConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GemmaConfig, Gemma2Config, GlmConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, GPTJConfig, IBertConfig, JambaConfig, JetMoeConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LEDConfig, LiltConfig, LlamaConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MBartConfig, MegaConfig, MegatronBertConfig, MistralConfig, MixtralConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, MT5Config, MvpConfig, NemotronConfig, NezhaConfig, NystromformerConfig, OpenLlamaConfig, OpenAIGPTConfig, OPTConfig, PerceiverConfig, PersimmonConfig, PhiConfig, Phi3Config, PhimoeConfig, PLBartConfig, QDQBertConfig, Qwen2Config, Qwen2MoeConfig, ReformerConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, StableLmConfig, Starcoder2Config, T5Config, TapasConfig, TransfoXLConfig, UMT5Config, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig, ZambaConfig.
2024-12-08 18:55:31,266 [WARNING]  * Debugger is active!
2024-12-08 18:55:31,284 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 19:04:49,930 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 19:04:51,633 [INFO]  * Restarting with stat
2024-12-08 19:29:03,836 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-08 19:29:03,838 [INFO] [33mPress CTRL+C to quit[0m
2024-12-08 19:29:03,840 [INFO]  * Restarting with stat
2024-12-08 19:29:16,229 [WARNING]  * Debugger is active!
2024-12-08 19:29:16,249 [INFO]  * Debugger PIN: 412-392-676
2024-12-08 19:29:28,338 [INFO] Prediction started.
2024-12-08 19:29:28,338 [ERROR] Prediction error: name 'load_smiles_data' is not defined
2024-12-08 19:29:28,339 [INFO] 127.0.0.1 - - [08/Dec/2024 19:29:28] "[35m[1mPOST /predict HTTP/1.1[0m" 202 -
2024-12-08 19:29:39,578 [INFO] 127.0.0.1 - - [08/Dec/2024 19:29:39] "[35m[1mPOST /train HTTP/1.1[0m" 202 -
2024-12-08 19:32:28,148 [INFO]  * Detected change in 'D:\\Material-Recognition-Using-XAI-Bachelor-Thesis-1\\Model\\src\\Transformer_model\\app.py', reloading
2024-12-08 19:32:29,326 [INFO]  * Restarting with stat
2024-12-08 19:37:59,317 [INFO] [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on http://127.0.0.1:5000
2024-12-08 19:37:59,318 [INFO] [33mPress CTRL+C to quit[0m
2024-12-08 19:37:59,321 [INFO]  * Restarting with stat
